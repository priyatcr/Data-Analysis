# Assign1

wiki = read.csv("wiki.csv", stringsAsFactors=FALSE)
wiki$Vandal = as.factor(wiki$Vandal)
table(wiki$Vandal)
library(tm)
library(SnowballC)
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded = tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded,stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
sparseAdded = removeSparseTerms(dtmAdded, 0.997)
sparseAdded
wordsAdded = as.data.frame(as.matrix(sparseAdded))
colnames(wordsAdded) = paste("A",colnames(wordsAdded))
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corpusRemoved = tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved = tm_map(corpusRemoved,stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
sparseRemoved = removeSparseTerms(dtmRemoved, 0.997)
sparseRemoved
wordsRemoved = as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved)=paste("R",colnames(wordsRemoved))
wikiwords = cbind(wordsAdded,wordsRemoved)
wikiwords$Vandal = wiki$Vandal
set.seed(123)
split = sample.split(wikiwords$Vandal, SplitRatio =0.7)
trainwiki = subset(wikiwords, split==TRUE)
testwiki = subset(wikiwords, split==FALSE)
table(testwiki$Vandal)
CARTwiki = rpart(Vandal~.,data=trainwiki, method="class")
predwiki = predict(CARTwiki, newdata=testwiki, type="class")
table(testwiki$Vandal, predwiki)
prp(CARTwiki)
wikiwords2=wikiwords
wikiwords2$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE),1,0)
table(wikiwords2$HTTP)
trainwiki2 = subset(wikiwords2, split==TRUE)
testwiki2 = subset(wikiwords2, split==FALSE)
CARTwiki2 = rpart(Vandal~.,data=trainwiki2, method="class")
predwiki2 = predict(CARTwiki2, newdata=testwiki2, type="class")
table(testwiki2$Vandal, predwiki2)
wikiwords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiwords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))
mean(wikiwords2$NumWordsAdded)
trainwiki2 = subset(wikiwords2, split==TRUE)
testwiki2 = subset(wikiwords2, split==FALSE)
CARTwiki2 = rpart(Vandal~.,data=trainwiki2, method="class")
predwiki2 = predict(CARTwiki2, newdata=testwiki2, type="class")
table(testwiki2$Vandal, predwiki2)
wikiwords3=wikiwords2
wikiwords3$Minor=wiki$Minor
wikiwords3$Loggedin = wiki$Loggedin
trainwiki3 = subset(wikiwords3, split==TRUE)
testwiki3 = subset(wikiwords3, split==FALSE)
CARTwiki3 = rpart(Vandal~.,data=trainwiki3, method="class")
predwiki3 = predict(CARTwiki3, newdata=testwiki3, type="class")
table(testwiki3$Vandal, predwiki3)
prp(CARTwiki3)

# 2
trials = read.csv("clinical_trial.csv",stringsAsFactors=FALSE)
summary(nchar(trials$abstract))
max(nchar(trials$abstract))
table(nchar(trials$abstract) == 0)
sum(trials$abstract == 0)
which.min(nchar(trials$title))
trials$title[1258]
library(tm)
library(SnowballC)
corpusTitle = Corpus(VectorSource(trials$title))
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusTitle = tm_map(corpusTitle,tolower)
corpusAbstract = tm_map(corpusAbstract,tolower)
corpusTitle = tm_map(corpusTitle, removePunctuation)
corpusAbstract = tm_map(corpusAbstract, removePunctuation)
corpusTitle = tm_map(corpusTitle,removeWords,stopwords("english"))
corpusAbstract = tm_map(corpusAbstract,removeWords,stopwords("english"))
corpusTitle = tm_map(corpusTitle,stemDocument)
corpusAbstract = tm_map(corpusAbstract,stemDocument)
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
dtmTitle = removeSparseTerms(dtmTitle,0.95)
dtmAbstract = removeSparseTerms(dtmAbstract, 0.95)
dtmTitle = as.data.frame(as.matrix(dtmTitle))
dtmAbstract = as.data.frame(as.matrix(dtmAbstract))
sort(colSums(dtmAbstract))
#csAbstract = colSums(dtmAbstract)
#which.max(csAbstract)
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtm = cbind(dtmTitle,dtmAbstract)
dtm$trial = trials$trial
library(caTools)
set.seed(144)
split= sample.split(dtm$trial, SplitRatio = 0.70)
train = subset(dtm, split==TRUE)
test = subset(dtm, split==FALSE)
table(train$trial)
library(rpart)
library(rpart.plot)
trialCART = rpart(trial~.,data=train, method="class")
prp(trialCART)
pred1 = predict(trialCART)
prob = pred1[,2]
max(prob)
predCART = predict(trialCART, type="class")
table(train$trial, predCART)
pred1=predict(trialCART, newdata=test)
predTest=pred1[,2]
table(test$trial, predTest>=0.5)
library(ROCR)
predROCR = prediction(predTest, test$trial)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values

#3
emails = read.csv("emails.csv",stringsAsFactors=FALSE)
str(emails)
table(emails$spam)
which.max(nchar(emails$text))
nchar(emails$text[2651])
which.min(nchar(emails$text))
nchar(emails$text[1992])
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
sort(colSums(emailsSparse))
sort(colSums(subset(emailsSparse, spam == 0)))
sort(colSums(subset(emailsSparse, spam == 1)))
emailsSparse$spam = as.factor(emailsSparse$spam)
library(caTools)
set.seed(123)
split = sample.split(emailsSparse$spam, SplitRatio=0.7)
train = subset(emailsSparse, split==TRUE)
test=subset(emailsSparse, split==FALSE)
spamLog = glm(spam~., data=train, family="binomial")
library(rpart)
library(rpart.plot)
spamCART = rpart(spam~.,data=train, method="class")
library(randomForest)
set.seed(123)
colnames(train)=make.names(colnames(train))
spamRF = randomForest(spam ~ ., data=train, method="class")
predLog = predict(spamLog, type="response")
sum(predLog<0.00001)
sum(predLog>0.99999)
sum(predLog>0.00001 & predLog<0.99999)
predCART = predict(spamCART, type="class")
#predCART.pred = predCART[,2]
predRF = predict(spamRF, type="prob")
predRF.prob = predRF[,2]
prp(spamCART)
predROCR = prediction(predLog, train$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
table(train$spam, predLog>0.5)
table(train$spam, predCART)
predCART1 = predict(spamCART)
predROCR1 = prediction(predCART1, train$spam)
predROCR1 = prediction(predCART1[,2], train$spam)
perfROCR1 = performance(predROCR1, "tpr", "fpr")
predROCRtest = prediction(predLog, test$spam)
perfROCRtest = performance(predROCRtest, "tpr", "fpr")
performance(predROCRtest, "auc")@y.values
performance(predROCR1, "auc")@y.values #or as.numeric(performance(predROCR1, "auc")@y.values)
table(train$spam,predRF.prob>0.5)
predROCR2 = prediction(predRF.prob, train$spam)
perfROCR2 = performance(predROCR2, "tpr", "fpr")
performance(predROCR2, "auc")@y.values
colnames(test)=make.names(colnames(test))
predLog = predict(spamLog, newdata=test,type="response")
table(test$spam, predLog>0.5)
predCART = predict(spamCART, newdata=test)
prob = predCART[,2]
table(test$spam, prob>0.5)

predCART3 = predict(spamCART, newdata=test, type="class")
predROCR3 = prediction(predCART3, test$spam)
perfROCR3 = performance(predROCR1, "tpr", "fpr")
performance(predROCR3, "auc")@y.values

#4
wordCount = rowSums(as.matrix(dtm))
hist(wordCount)
hist(log(wordCount))
logWordCount = log(wordCount)
emailsSparse$logWordCount = logWordCount
boxplot(logWordCount~spam, data=emailsSparse)
library(caTools)
set.seed(123)
split = sample.split(emailsSparse$spam, SplitRatio=0.7)
train2 = subset(emailsSparse, split==TRUE)
test2=subset(emailsSparse, split==FALSE)
library(rpart)
library(rpart.plot)
spamCART2 = rpart(spam~.,data=train2, method="class")
library(randomForest)
set.seed(123)
colnames(train2)=make.names(colnames(train2))
spamRF2 = randomForest(spam ~ ., data=train2, method="class")
prp(spamCART2)
predCAR = predict(spamCART2, newdata=test2)
table(test2$spam, predCAR[,2]>0.5)
colnames(test2)=make.names(colnames(test2))
predRF = predict(spamRF2, newdata=test2, type="prob")[,2]
table(test2$spam, predRF>0.5)
library(ROCR)
predROCR4 = prediction(predCAR[,2], test2$spam)
perfROCR4 = performance(predROCR4, "tpr", "fpr")
performance(predROCR4, "auc")@y.values
predROCRRF4 = prediction(predRF, test2$spam) 
perfRFROCR4 = performance(predROCRRF4, "tpr", "fpr")
performance(predROCRRF4, "auc")@y.values
install.packages("RTextTools")
library(RTextTools)
dtm2gram = create_matrix(as.character(corpus),ngramLength=2)
dtm2gram
spdtm2gram = removeSparseTerms(dtm2gram, 0.95)
spdtm2gram
emailsSparse2gram = as.data.frame(as.matrix(spdtm2gram))
colnames(emailsSparse2gram)=make.names(colnames(emailsSparse2gram))
emailsCombined = cbind(emailsSparse, emailsSparse2gram)
trainCombined = subset(emailsCombined, split==TRUE)
testCombined = subset(emailsCombined, split==FALSE)
spamCARTcombined =rpart(spam~., data=trainCombined)
set.seed(123)
colnames(trainCombined)=make.names(colnames(trainCombined))
spamRFcombined = randomForest(spam~., data=trainCombined, method="class")
prp(spamCARTcombined,varlen=0) #varlen=0 to display full variable names
predCARcombined = predict(spamCARTcombined, newdata=testCombined)
table(testCombined$spam,predCARcombined[,2]>0.5)
predROCRcombined = prediction(predCARcombined[,2],testCombined$spam)
as.numeric((performance(predROCRcombined, "auc"))@y.values)
colnames(testCombined)=make.names(colnames(testCombined))
predRFcombined = predict(spamRFcombined, newdata=testCombined,type="prob")
predRFcombined.prob = predRFcombined[,2]
table(testCombined$spam,predRFcombined.prob>0.5)
predROCRRFc = prediction(predRFcombined.prob,testCombined$spam)
as.numeric((performance(predROCRRFc, "auc"))@y.values)